神经网络的分布式训练有两种方案：模型并行(Model Parallelism)和数据并行(Data Parallelism)
![](/assets/twoparallel.png)
两种方案也可以结合在一起，比如一台机器的多卡之间是模型并行，不同机器之间做数据并行。

## 模型并行
不同的机器处理模型中的一部分（比如不同的Layer放在不同的机器上计算），一般用于处理非常大的模型。

## 数据并行
不同的机器有相同的完整模型的一份拷贝，但输入数据被切分，并由不同的机器处理。每个机器训练自己的模型，然后不同机器的模型做融合。

* 根据融合内容的不同，可以融合参数(Parameter)、梯度(Gradient)或参数的更新量(Parameter Update)
* 根据融合方式的不同，可以采用同步(Synchronous)并行和异步(Asynchronous)并行的方式
* 根据实现方式，可以采用MPI并行、参数服务器(Parameter Server)或分布式更新

**初始化问题**：数据并行要求每个机器拥有相同的模型，所以在初始化模型参数时，需要保证所有机器的初始化结果相同。

### 同步数据并行
各个机器训练自己模型的梯度，然后所有机器的梯度做平均操作并作为每个模型的更新梯度，最后每个模型根据梯度做参数更新。

平均操作一般使用MPI的Allreduce操作完成，也可以用参数服务器实现。Allreduce不能使用平均操作，所以用SUM操作代替，每个机器计算的梯度在做SUM操作之前先除以机器数。

**优势**：
* 算法稳定

**劣势**：
* 通信时间随节点数增加而增加
* 所有节点需要同步，最慢节点会拖慢系统速度

### 异步数据并行
每个机器从参数服务器中获取模型参数，然后训练自己的模型，再将更新的梯度传回参数服务器。

**优势**：
* 运行速度比同步并行快
* 每个机器的参数更新都能及时被其他机器获得。在同步并行模式下，n台机器都是用的上一轮(n个batch)的参数值

**劣势**：
* 旧参数问题(stale gradient problem)：在某个机器计算梯度值时，参数服务器中的参数已经被更新了。将梯度值返回给参数服务器时，此时的梯度值是若干次更新前的参数的梯度值
* 收敛速度(相同epoch时)不如同步数据并行，甚至最终都无法达到同步并行的准确度
* 参数服务器的带宽或计算速度可能成为性能瓶颈（使用多个参数服务器，每个负责更新一部分模型参数）

Soft synchronization：每次参数服务器在获得s次梯度更新后再更新参数，其中`(1<=s<=n)`

